{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ce5a6ca-58cc-4d8f-90a2-482f80e1b444",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lineage Demo\n",
    "\n",
    "Source Dataset: https://www.kaggle.com/datasets/pschale/mlb-pitch-data-20152018?select=2019_atbats.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc50d35f-2827-4600-8576-e16c2e3c40b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SETUP: Specify Catalog and Schema to use"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "target_catalog = \"lgeorge\"\n",
    "target_schema = \"lineage_demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c265ff95-540e-488d-b9f6-dca79f4359c9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create resources if they don't exist"
    }
   },
   "outputs": [],
   "source": [
    "%py\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS {target_catalog}\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS {target_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6c0194-3176-4ca3-ab74-bf9b3c6a3c0b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select Catalog and Schema Specified above"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(f\"USE CATALOG {target_catalog}\")\n",
    "spark.sql(f\"USE SCHEMA {target_schema}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b6a050-c810-4e04-8c31-b05a738d33a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Volume that will hold raw data"
    }
   },
   "outputs": [],
   "source": [
    "CREATE VOLUME IF NOT EXISTS raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdae65d6-8a19-4919-aa4f-87f91733e33b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Unzip the file and put csv files back in volume"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from zipfile import ZipFile \n",
    "  \n",
    "# loading the temp.zip and creating a zip object \n",
    "with ZipFile(\"/Volumes/lgeorge/lineage_demo/raw_data/data_files.zip\", 'r') as zipped_file: \n",
    "  \n",
    "    # Extracting all the members of the zip  \n",
    "    # into a specific location. \n",
    "    zipped_file.extractall( \n",
    "        path=\"/Volumes/lgeorge/lineage_demo/raw_data/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd627e9a-4083-4e2d-a79e-1e8b262f580c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in CSV files and save them as Delta Lake tables"
    }
   },
   "outputs": [],
   "source": [
    "%py\n",
    "import glob\n",
    "\n",
    "for filepath in glob.glob('/Volumes/lgeorge/lineage_demo/raw_data/*.csv'):\n",
    "    if '2019' not in filepath:\n",
    "      \n",
    "      table_name = filepath.split(\"/\")[-1][:-4]\n",
    "\n",
    "      df = spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).load(filepath)\n",
    "      df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deb3b89a-16d1-4d74-bf16-ae02218c7115",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create atbat_general table"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE atbat_general\n",
    "AS\n",
    "SELECT\n",
    "  ab.g_id as game_id,\n",
    "  ab.ab_id,\n",
    "  concat_ws(\" \", b.first_name, b.last_name) as batter_name,\n",
    "  concat_ws(\" \", p.first_name, p.last_name) as pitcher_name,  \n",
    "  g.umpire_HP,\n",
    "  ab.event as atbat_event,\n",
    "  ab.inning,\n",
    "  ab.o as out,\n",
    "  ab.top as top_of_inning,\n",
    "  g.home_team,\n",
    "  g.away_team,\n",
    "  g.weather,\n",
    "  g.wind\n",
    "FROM\n",
    "  atbats ab\n",
    "LEFT JOIN player_names b ON ab.batter_id = b.id\n",
    "LEFT JOIN player_names p ON ab.pitcher_id = p.id\n",
    "LEFT JOIN games g ON ab.g_id = g.g_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df598d07-5f13-42ac-ae8b-8d951c7ceb88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE ejected_players_summary\n",
    "AS\n",
    "SELECT\n",
    "  e.player_id as player_id,\n",
    "  concat_ws(\" \", p.first_name, p.last_name) as ejected_player_name,\n",
    "  count(*) as ejected_count\n",
    "FROM\n",
    "  player_names p\n",
    "INNER JOIN ejections e ON p.id = e.player_id\n",
    "GROUP BY player_id, ejected_player_name\n",
    "ORDER BY ejected_count DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f534d472-0beb-481a-b59c-6bc802e5186e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM ejections;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "274c7390-5866-4dce-be27-05836df5115c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM lgeorge.lineage_demo.pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6db67716-3838-48ea-bc88-bfad1ab6f2b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Lineage_Demo",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
